# Projeto-Machine-Learning

Neste projeto acadêmico, da disciplina de aprendizagem de máquina do mestrado em ciência da computação pelo CIn-UFPE, utilizamos 3 conjuntos de dados do dataset [mfeature](https://archive.ics.uci.edu/dataset/72/multiple+features). Este dataset consiste em caracteristicas de numerais de 0-9 escritos a mão. Neste projeto, Inicialmente fazemos uma exploração dos dados, verificamos se há valores nulos, e então criamos nosso dataframe alvo, que irá consistir das classes de 0-9, a qual queremos classificar. 

Realizo divisão de dados, sendo 70% de treino, 30% de teste. E logo em seguida padronizo esses dados. São treinados quatro modelos de classificação diferentes, sendo eles: o K-nearest-neighbors, Bayesian Gaussian, Parzen Window e Logistic Regression, Ao final uso o Voting Classifier do Scikit-learn com argumento de voto majoritário para combinar esses 4 classificadores. Para treinar os modelos utilizo um gridsearch em busca dos melhores hiperparametros de cada algoritmo. Para o dataset mfeat-fac conseguimos 100% de acurácia no conjunto de treino e 96,50% de acurácia no conjunto de teste, O que são resultados muito bons para classificação! Para treinar cada modelo utilizei validação cruzada estratificada (30x10) folds. Também calculei estimativas pontuais e intervalo de confiança para cada métrica, sendo elas: Acurácia, recall, f1 e precisão. Com os resultados da validação cruzada, realizei o teste estatistíco de Friedman, verificando P_valor < 0.05, Logo há diferença significativa entre cada métrica dos algoritmos. Sendo assim realizei o posthoc de Nemenyi, e por fim rankeei os algoritmos a parte do voting classifier, para checar quem obteve melhores desempenhos. Assim sendo o KNN e a Regressão logistica obtiveram os melhores resultados. Variando um pouco a depender da métrica e do dataset, mas sempre em primeiro e segundo lugares.
